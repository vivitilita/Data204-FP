{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>trainer</th>\n",
       "      <th>Analytic_W1</th>\n",
       "      <th>Independent_W1</th>\n",
       "      <th>Determined_W1</th>\n",
       "      <th>Professional_W1</th>\n",
       "      <th>Studious_W1</th>\n",
       "      <th>Imaginative_W1</th>\n",
       "      <th>Analytic_W2</th>\n",
       "      <th>Independent_W2</th>\n",
       "      <th>...</th>\n",
       "      <th>Determined_W9</th>\n",
       "      <th>Professional_W9</th>\n",
       "      <th>Studious_W9</th>\n",
       "      <th>Imaginative_W9</th>\n",
       "      <th>Analytic_W10</th>\n",
       "      <th>Independent_W10</th>\n",
       "      <th>Determined_W10</th>\n",
       "      <th>Professional_W10</th>\n",
       "      <th>Studious_W10</th>\n",
       "      <th>Imaginative_W10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quintus Penella</td>\n",
       "      <td>Gregor Gomez</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Simon Murrey</td>\n",
       "      <td>Gregor Gomez</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gustaf Lude</td>\n",
       "      <td>Gregor Gomez</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yolanda Fosse</td>\n",
       "      <td>Gregor Gomez</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lynnett Swin</td>\n",
       "      <td>Gregor Gomez</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>Moritz Mosedall</td>\n",
       "      <td>Mohammad Velazquez</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>Chaim Inseal</td>\n",
       "      <td>Mohammad Velazquez</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>Gertruda Syddie</td>\n",
       "      <td>Mohammad Velazquez</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>Thom Derwin</td>\n",
       "      <td>Mohammad Velazquez</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>Godfry Sephton</td>\n",
       "      <td>Mohammad Velazquez</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>397 rows Ã— 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                name             trainer  Analytic_W1  Independent_W1  \\\n",
       "0    Quintus Penella        Gregor Gomez            1               2   \n",
       "1       Simon Murrey        Gregor Gomez            6               1   \n",
       "2        Gustaf Lude        Gregor Gomez            6               4   \n",
       "3      Yolanda Fosse        Gregor Gomez            2               1   \n",
       "4       Lynnett Swin        Gregor Gomez            2               2   \n",
       "..               ...                 ...          ...             ...   \n",
       "392  Moritz Mosedall  Mohammad Velazquez            1               1   \n",
       "393     Chaim Inseal  Mohammad Velazquez            1               3   \n",
       "394  Gertruda Syddie  Mohammad Velazquez            3               1   \n",
       "395      Thom Derwin  Mohammad Velazquez            3               7   \n",
       "396   Godfry Sephton  Mohammad Velazquez            4               2   \n",
       "\n",
       "     Determined_W1  Professional_W1  Studious_W1  Imaginative_W1  Analytic_W2  \\\n",
       "0                2                1            2               2          NaN   \n",
       "1                1                2            4               2          3.0   \n",
       "2                1                1            2               3          1.0   \n",
       "3                2                3            3               3          4.0   \n",
       "4                4                5            1               2          3.0   \n",
       "..             ...              ...          ...             ...          ...   \n",
       "392              5                1            2               6          5.0   \n",
       "393              3                4            1               2          3.0   \n",
       "394              2                8            1               4          2.0   \n",
       "395              3                3            3               1          2.0   \n",
       "396              5                1            1               2          4.0   \n",
       "\n",
       "     Independent_W2  ...  Determined_W9  Professional_W9  Studious_W9  \\\n",
       "0               NaN  ...            NaN              NaN          NaN   \n",
       "1               1.0  ...            NaN              NaN          NaN   \n",
       "2               1.0  ...            NaN              NaN          NaN   \n",
       "3               2.0  ...            NaN              NaN          NaN   \n",
       "4               2.0  ...            NaN              NaN          NaN   \n",
       "..              ...  ...            ...              ...          ...   \n",
       "392             3.0  ...            NaN              NaN          NaN   \n",
       "393             3.0  ...            NaN              NaN          NaN   \n",
       "394             4.0  ...            NaN              NaN          NaN   \n",
       "395             7.0  ...            NaN              NaN          NaN   \n",
       "396             1.0  ...            NaN              NaN          NaN   \n",
       "\n",
       "     Imaginative_W9  Analytic_W10  Independent_W10  Determined_W10  \\\n",
       "0               NaN           NaN              NaN             NaN   \n",
       "1               NaN           NaN              NaN             NaN   \n",
       "2               NaN           NaN              NaN             NaN   \n",
       "3               NaN           NaN              NaN             NaN   \n",
       "4               NaN           NaN              NaN             NaN   \n",
       "..              ...           ...              ...             ...   \n",
       "392             NaN           NaN              NaN             NaN   \n",
       "393             NaN           NaN              NaN             NaN   \n",
       "394             NaN           NaN              NaN             NaN   \n",
       "395             NaN           NaN              NaN             NaN   \n",
       "396             NaN           NaN              NaN             NaN   \n",
       "\n",
       "     Professional_W10  Studious_W10  Imaginative_W10  \n",
       "0                 NaN           NaN              NaN  \n",
       "1                 NaN           NaN              NaN  \n",
       "2                 NaN           NaN              NaN  \n",
       "3                 NaN           NaN              NaN  \n",
       "4                 NaN           NaN              NaN  \n",
       "..                ...           ...              ...  \n",
       "392               NaN           NaN              NaN  \n",
       "393               NaN           NaN              NaN  \n",
       "394               NaN           NaN              NaN  \n",
       "395               NaN           NaN              NaN  \n",
       "396               NaN           NaN              NaN  \n",
       "\n",
       "[397 rows x 63 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign the s3 bucket to a variable\n",
    "bucket_name = 'data-eng-204-final-project'\n",
    "folder_path = 'Academy/'\n",
    "\n",
    "def get_s3_objects(bucket_name, folder_path):\n",
    "    \"\"\"\n",
    "    Returns a Pandas DataFrame by reading CSV files from a specified S3 bucket and prefix.\n",
    "\n",
    "    Args:\n",
    "        bucket_name (str): The name of the S3 bucket.\n",
    "        folder_path (str): The prefix of the S3 objects to read.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A merged Pandas DataFrame containing the contents of all the CSV files in the specified S3 bucket and prefix.\n",
    "    \"\"\"\n",
    "    # Create an S3 client object\n",
    "    s3_client = boto3.client('s3')\n",
    "\n",
    "    # List all objects in the specified S3 bucket and prefix\n",
    "    objects = s3_client.list_objects(Bucket=bucket_name, Prefix=folder_path)\n",
    "\n",
    "    # Extract the keys of all CSV objects in the S3 bucket and prefix\n",
    "    keys = [obj['Key'] for obj in objects['Contents'] if obj['Key']]\n",
    "\n",
    "    # Create a list to store Pandas DataFrames for each CSV object\n",
    "    dfs = []\n",
    "\n",
    "    # Iterate over each CSV object, read it into a Pandas DataFrame, and append it to the list of DataFrames\n",
    "    for key in keys:\n",
    "        # Get the CSV object from S3\n",
    "        obj = s3_client.get_object(Bucket=bucket_name, Key=key)\n",
    "\n",
    "        # Read the CSV object into a Pandas DataFrame\n",
    "        df = pd.read_csv(obj['Body'], delimiter=',')\n",
    "\n",
    "        # Add a column to the DataFrame with the name of the file\n",
    "        df['filename'] = key.split('/')[-1]\n",
    "\n",
    "        # Append the DataFrame to the list of DataFrames\n",
    "        dfs.append(df)\n",
    "\n",
    "    # Concatenate all the DataFrames into a single DataFrame\n",
    "    final_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # Return the merged DataFrame\n",
    "    return final_df\n",
    "\n",
    "raw_df = get_s3_objects(bucket_name,folder_path)\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>trainer</th>\n",
       "      <th>course</th>\n",
       "      <th>start_date</th>\n",
       "      <th>Analytic_W1</th>\n",
       "      <th>Independent_W1</th>\n",
       "      <th>Determined_W1</th>\n",
       "      <th>Professional_W1</th>\n",
       "      <th>Studious_W1</th>\n",
       "      <th>Imaginative_W1</th>\n",
       "      <th>...</th>\n",
       "      <th>Determined_W9</th>\n",
       "      <th>Professional_W9</th>\n",
       "      <th>Studious_W9</th>\n",
       "      <th>Imaginative_W9</th>\n",
       "      <th>Analytic_W10</th>\n",
       "      <th>Independent_W10</th>\n",
       "      <th>Determined_W10</th>\n",
       "      <th>Professional_W10</th>\n",
       "      <th>Studious_W10</th>\n",
       "      <th>Imaginative_W10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pyotr De Zuani</td>\n",
       "      <td>Trixie Orange</td>\n",
       "      <td>Data</td>\n",
       "      <td>2019-02-18</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vince Scott</td>\n",
       "      <td>Trixie Orange</td>\n",
       "      <td>Data</td>\n",
       "      <td>2019-02-18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kellie Althorp</td>\n",
       "      <td>Trixie Orange</td>\n",
       "      <td>Data</td>\n",
       "      <td>2019-02-18</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aida Bothams</td>\n",
       "      <td>Trixie Orange</td>\n",
       "      <td>Data</td>\n",
       "      <td>2019-02-18</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nettie Civitillo</td>\n",
       "      <td>Trixie Orange</td>\n",
       "      <td>Data</td>\n",
       "      <td>2019-02-18</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               name        trainer course  start_date  Analytic_W1  \\\n",
       "0    Pyotr De Zuani  Trixie Orange   Data  2019-02-18            1   \n",
       "1       Vince Scott  Trixie Orange   Data  2019-02-18            1   \n",
       "2    Kellie Althorp  Trixie Orange   Data  2019-02-18            3   \n",
       "3      Aida Bothams  Trixie Orange   Data  2019-02-18            4   \n",
       "4  Nettie Civitillo  Trixie Orange   Data  2019-02-18            5   \n",
       "\n",
       "   Independent_W1  Determined_W1  Professional_W1  Studious_W1  \\\n",
       "0               3              4                2            2   \n",
       "1               1              4                3            3   \n",
       "2               4              1                1            5   \n",
       "3               2              2                3            3   \n",
       "4               4              3                1            1   \n",
       "\n",
       "   Imaginative_W1  ...  Determined_W9  Professional_W9  Studious_W9  \\\n",
       "0               2  ...            NaN              NaN          NaN   \n",
       "1               4  ...            NaN              NaN          NaN   \n",
       "2               2  ...            NaN              NaN          NaN   \n",
       "3               1  ...            NaN              NaN          NaN   \n",
       "4               6  ...            NaN              NaN          NaN   \n",
       "\n",
       "   Imaginative_W9  Analytic_W10  Independent_W10  Determined_W10  \\\n",
       "0             NaN           NaN              NaN             NaN   \n",
       "1             NaN           NaN              NaN             NaN   \n",
       "2             NaN           NaN              NaN             NaN   \n",
       "3             NaN           NaN              NaN             NaN   \n",
       "4             NaN           NaN              NaN             NaN   \n",
       "\n",
       "   Professional_W10  Studious_W10  Imaginative_W10  \n",
       "0               NaN           NaN              NaN  \n",
       "1               NaN           NaN              NaN  \n",
       "2               NaN           NaN              NaN  \n",
       "3               NaN           NaN              NaN  \n",
       "4               NaN           NaN              NaN  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_course_dataframe(bucket_name, course_name):\n",
    "    \"\"\"\n",
    "    Returns a Pandas DataFrame containing data from all CSV files corresponding to a specified course in an S3 bucket.\n",
    "\n",
    "    Args:\n",
    "        bucket_name (str): The name of the S3 bucket.\n",
    "        course_name (str): The name of the course.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A merged Pandas DataFrame containing the contents of all the CSV files corresponding to the specified course in the specified S3 bucket.\n",
    "    \"\"\"\n",
    "    # Define the prefix of the S3 objects for the specified course\n",
    "    folder_path = f'Academy/{course_name}'\n",
    "\n",
    "    # Get a Pandas DataFrame by reading CSV files from the specified S3 bucket and prefix\n",
    "    df = get_s3_objects(bucket_name, folder_path)\n",
    "\n",
    "    # Extract course and started_date information from the filename and add them as separate columns\n",
    "    df['course'] = df['filename'].str.extract(r'^(.*?)_')\n",
    "    df['start_date'] = df['filename'].str.extract(r'_(\\d{4}-\\d{2}-\\d{2})\\.csv$')\n",
    "\n",
    "    # Reorder the columns of the DataFrame for readability and consistency\n",
    "    cols = df.columns.tolist()\n",
    "    cols.remove('trainer')\n",
    "    cols.insert(1, 'trainer')\n",
    "    cols.remove('course')\n",
    "    cols.insert(2, 'course')\n",
    "    cols.remove('start_date')\n",
    "    cols.insert(3, 'start_date')\n",
    "    df = df.reindex(columns=cols)\n",
    "\n",
    "    # Return the updated DataFrame\n",
    "    return df\n",
    "\n",
    "df = get_course_dataframe('data-eng-204-final-project', 'Data')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>trainer</th>\n",
       "      <th>course</th>\n",
       "      <th>start_date</th>\n",
       "      <th>Analytic_W1</th>\n",
       "      <th>Independent_W1</th>\n",
       "      <th>Determined_W1</th>\n",
       "      <th>Professional_W1</th>\n",
       "      <th>Studious_W1</th>\n",
       "      <th>Imaginative_W1</th>\n",
       "      <th>...</th>\n",
       "      <th>Determined_W9</th>\n",
       "      <th>Professional_W9</th>\n",
       "      <th>Studious_W9</th>\n",
       "      <th>Imaginative_W9</th>\n",
       "      <th>Analytic_W10</th>\n",
       "      <th>Independent_W10</th>\n",
       "      <th>Determined_W10</th>\n",
       "      <th>Professional_W10</th>\n",
       "      <th>Studious_W10</th>\n",
       "      <th>Imaginative_W10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quintus Penella</td>\n",
       "      <td>Gregor Gomez</td>\n",
       "      <td>Business</td>\n",
       "      <td>2019-02-11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Simon Murrey</td>\n",
       "      <td>Gregor Gomez</td>\n",
       "      <td>Business</td>\n",
       "      <td>2019-02-11</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gustaf Lude</td>\n",
       "      <td>Gregor Gomez</td>\n",
       "      <td>Business</td>\n",
       "      <td>2019-02-11</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yolanda Fosse</td>\n",
       "      <td>Gregor Gomez</td>\n",
       "      <td>Business</td>\n",
       "      <td>2019-02-11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lynnett Swin</td>\n",
       "      <td>Gregor Gomez</td>\n",
       "      <td>Business</td>\n",
       "      <td>2019-02-11</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>Moritz Mosedall</td>\n",
       "      <td>Mohammad Velazquez</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>Chaim Inseal</td>\n",
       "      <td>Mohammad Velazquez</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>Gertruda Syddie</td>\n",
       "      <td>Mohammad Velazquez</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>Thom Derwin</td>\n",
       "      <td>Mohammad Velazquez</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>Godfry Sephton</td>\n",
       "      <td>Mohammad Velazquez</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>397 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                name             trainer       course  start_date  \\\n",
       "0    Quintus Penella        Gregor Gomez     Business  2019-02-11   \n",
       "1       Simon Murrey        Gregor Gomez     Business  2019-02-11   \n",
       "2        Gustaf Lude        Gregor Gomez     Business  2019-02-11   \n",
       "3      Yolanda Fosse        Gregor Gomez     Business  2019-02-11   \n",
       "4       Lynnett Swin        Gregor Gomez     Business  2019-02-11   \n",
       "..               ...                 ...          ...         ...   \n",
       "392  Moritz Mosedall  Mohammad Velazquez  Engineering  2019-12-30   \n",
       "393     Chaim Inseal  Mohammad Velazquez  Engineering  2019-12-30   \n",
       "394  Gertruda Syddie  Mohammad Velazquez  Engineering  2019-12-30   \n",
       "395      Thom Derwin  Mohammad Velazquez  Engineering  2019-12-30   \n",
       "396   Godfry Sephton  Mohammad Velazquez  Engineering  2019-12-30   \n",
       "\n",
       "     Analytic_W1  Independent_W1  Determined_W1  Professional_W1  Studious_W1  \\\n",
       "0              1               2              2                1            2   \n",
       "1              6               1              1                2            4   \n",
       "2              6               4              1                1            2   \n",
       "3              2               1              2                3            3   \n",
       "4              2               2              4                5            1   \n",
       "..           ...             ...            ...              ...          ...   \n",
       "392            1               1              5                1            2   \n",
       "393            1               3              3                4            1   \n",
       "394            3               1              2                8            1   \n",
       "395            3               7              3                3            3   \n",
       "396            4               2              5                1            1   \n",
       "\n",
       "     Imaginative_W1  ...  Determined_W9  Professional_W9  Studious_W9  \\\n",
       "0                 2  ...            NaN              NaN          NaN   \n",
       "1                 2  ...            NaN              NaN          NaN   \n",
       "2                 3  ...            NaN              NaN          NaN   \n",
       "3                 3  ...            NaN              NaN          NaN   \n",
       "4                 2  ...            NaN              NaN          NaN   \n",
       "..              ...  ...            ...              ...          ...   \n",
       "392               6  ...            NaN              NaN          NaN   \n",
       "393               2  ...            NaN              NaN          NaN   \n",
       "394               4  ...            NaN              NaN          NaN   \n",
       "395               1  ...            NaN              NaN          NaN   \n",
       "396               2  ...            NaN              NaN          NaN   \n",
       "\n",
       "     Imaginative_W9  Analytic_W10  Independent_W10  Determined_W10  \\\n",
       "0               NaN           NaN              NaN             NaN   \n",
       "1               NaN           NaN              NaN             NaN   \n",
       "2               NaN           NaN              NaN             NaN   \n",
       "3               NaN           NaN              NaN             NaN   \n",
       "4               NaN           NaN              NaN             NaN   \n",
       "..              ...           ...              ...             ...   \n",
       "392             NaN           NaN              NaN             NaN   \n",
       "393             NaN           NaN              NaN             NaN   \n",
       "394             NaN           NaN              NaN             NaN   \n",
       "395             NaN           NaN              NaN             NaN   \n",
       "396             NaN           NaN              NaN             NaN   \n",
       "\n",
       "     Professional_W10  Studious_W10  Imaginative_W10  \n",
       "0                 NaN           NaN              NaN  \n",
       "1                 NaN           NaN              NaN  \n",
       "2                 NaN           NaN              NaN  \n",
       "3                 NaN           NaN              NaN  \n",
       "4                 NaN           NaN              NaN  \n",
       "..                ...           ...              ...  \n",
       "392               NaN           NaN              NaN  \n",
       "393               NaN           NaN              NaN  \n",
       "394               NaN           NaN              NaN  \n",
       "395               NaN           NaN              NaN  \n",
       "396               NaN           NaN              NaN  \n",
       "\n",
       "[397 rows x 65 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_all_courses_dataframe(bucket_name):\n",
    "    \"\"\"\n",
    "    Returns a merged Pandas DataFrame containing data from all CSV files corresponding to all courses in an S3 bucket.\n",
    "\n",
    "    Args:\n",
    "        bucket_name (str): The name of the S3 bucket.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A merged Pandas DataFrame containing the contents of all the CSV files corresponding to all the courses in the specified S3 bucket.\n",
    "    \"\"\"\n",
    "    # Get a Pandas DataFrame for each course and concatenate them into a single DataFrame\n",
    "    df_business = get_course_dataframe(bucket_name, 'Business')\n",
    "    df_data = get_course_dataframe(bucket_name, 'Data')\n",
    "    df_eng = get_course_dataframe(bucket_name, 'Engineering')\n",
    "    df_all_courses = pd.concat([df_business, df_data, df_eng], ignore_index=True)\n",
    "\n",
    "    # Return the merged DataFrame\n",
    "    return df_all_courses\n",
    "\n",
    "all_courses = get_all_courses_dataframe('data-eng-204-final-project')\n",
    "all_courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>trainer</th>\n",
       "      <th>course</th>\n",
       "      <th>start_date</th>\n",
       "      <th>score</th>\n",
       "      <th>trait</th>\n",
       "      <th>week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quintus Penella</td>\n",
       "      <td>Gregor Gomez</td>\n",
       "      <td>Business</td>\n",
       "      <td>2019-02-11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Analytic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Simon Murrey</td>\n",
       "      <td>Gregor Gomez</td>\n",
       "      <td>Business</td>\n",
       "      <td>2019-02-11</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Analytic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gustaf Lude</td>\n",
       "      <td>Gregor Gomez</td>\n",
       "      <td>Business</td>\n",
       "      <td>2019-02-11</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Analytic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yolanda Fosse</td>\n",
       "      <td>Gregor Gomez</td>\n",
       "      <td>Business</td>\n",
       "      <td>2019-02-11</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Analytic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lynnett Swin</td>\n",
       "      <td>Gregor Gomez</td>\n",
       "      <td>Business</td>\n",
       "      <td>2019-02-11</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Analytic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23815</th>\n",
       "      <td>Moritz Mosedall</td>\n",
       "      <td>Mohammad Velazquez</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Imaginative</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23816</th>\n",
       "      <td>Chaim Inseal</td>\n",
       "      <td>Mohammad Velazquez</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Imaginative</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23817</th>\n",
       "      <td>Gertruda Syddie</td>\n",
       "      <td>Mohammad Velazquez</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Imaginative</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23818</th>\n",
       "      <td>Thom Derwin</td>\n",
       "      <td>Mohammad Velazquez</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Imaginative</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23819</th>\n",
       "      <td>Godfry Sephton</td>\n",
       "      <td>Mohammad Velazquez</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Imaginative</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23820 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name             trainer       course  start_date  score  \\\n",
       "0      Quintus Penella        Gregor Gomez     Business  2019-02-11    1.0   \n",
       "1         Simon Murrey        Gregor Gomez     Business  2019-02-11    6.0   \n",
       "2          Gustaf Lude        Gregor Gomez     Business  2019-02-11    6.0   \n",
       "3        Yolanda Fosse        Gregor Gomez     Business  2019-02-11    2.0   \n",
       "4         Lynnett Swin        Gregor Gomez     Business  2019-02-11    2.0   \n",
       "...                ...                 ...          ...         ...    ...   \n",
       "23815  Moritz Mosedall  Mohammad Velazquez  Engineering  2019-12-30    NaN   \n",
       "23816     Chaim Inseal  Mohammad Velazquez  Engineering  2019-12-30    NaN   \n",
       "23817  Gertruda Syddie  Mohammad Velazquez  Engineering  2019-12-30    NaN   \n",
       "23818      Thom Derwin  Mohammad Velazquez  Engineering  2019-12-30    NaN   \n",
       "23819   Godfry Sephton  Mohammad Velazquez  Engineering  2019-12-30    NaN   \n",
       "\n",
       "             trait week  \n",
       "0         Analytic    1  \n",
       "1         Analytic    1  \n",
       "2         Analytic    1  \n",
       "3         Analytic    1  \n",
       "4         Analytic    1  \n",
       "...            ...  ...  \n",
       "23815  Imaginative   10  \n",
       "23816  Imaginative   10  \n",
       "23817  Imaginative   10  \n",
       "23818  Imaginative   10  \n",
       "23819  Imaginative   10  \n",
       "\n",
       "[23820 rows x 7 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalise_scores_df(all_courses):\n",
    "    \"\"\"\n",
    "    Normalizes the scores in the input DataFrame by melting the DataFrame and separating out the 'trait' and 'week' columns.\n",
    "\n",
    "    Args:\n",
    "        all_courses (pandas.DataFrame): The input DataFrame containing course scores.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The normalized DataFrame containing scores for each trait in each week for each student in each course.\n",
    "    \"\"\"\n",
    "    # Define the weeks and traits to be used in the DataFrame\n",
    "    weeks = [f'W{i}' for i in range(1, 11)]\n",
    "    traits = ['Analytic', 'Independent', 'Determined', 'Professional', 'Studious', 'Imaginative']\n",
    "    \n",
    "    # Define the id and value columns to be used in the melted DataFrame\n",
    "    id_vars = ['name', 'trainer', 'course', 'start_date']\n",
    "    value_vars = [f'{trait}_{week}' for trait in traits for week in weeks]\n",
    "    \n",
    "    # Melt the input DataFrame and separate out the 'trait' and 'week' columns\n",
    "    scores_df = pd.melt(all_courses, id_vars=id_vars, value_vars=value_vars, var_name='trait_week', value_name='score')\n",
    "    scores_df[['trait', 'week']] = scores_df['trait_week'].str.split('_W', expand=True)\n",
    "    scores_df.drop('trait_week', axis=1, inplace=True)\n",
    "    \n",
    "    # Return the normalised DataFrame\n",
    "    return scores_df\n",
    "\n",
    "normalised_df = normalise_scores_df(all_courses)\n",
    "normalised_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2019-02-11', '2019-03-18', '2019-04-15', '2019-05-20',\n",
       "       '2019-07-15', '2019-07-29', '2019-08-12', '2019-09-16',\n",
       "       '2019-10-21', '2019-11-18', '2019-12-30', '2019-02-18',\n",
       "       '2019-03-04', '2019-04-08', '2019-07-22', '2019-08-05',\n",
       "       '2019-08-19', '2019-09-23', '2019-10-28', '2019-12-16',\n",
       "       '2019-04-01', '2019-04-29', '2019-05-27', '2019-11-25'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Course enrollment date\n",
    "normalised_df['start_date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "course     \n",
       "Engineering    8340\n",
       "Data           8220\n",
       "Business       7260\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Course enrollment counts\n",
    "normalised_df[['course']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "course\n",
       "Data           5.342416\n",
       "Engineering    5.283641\n",
       "Business       5.170643\n",
       "Name: score, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean score values sorted by course\n",
    "normalised_df.groupby('course')['score'].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Gregor Gomez', 'Bruce Lugo', 'Neil Mccarthy', 'Rachel Richard',\n",
       "       'Hamzah Melia', 'Burhan Milner', 'Elly Kelly', 'Ely Kely',\n",
       "       'Trixie Orange', 'John Sandbox', 'Edward Reinhart', 'Lucy Foster',\n",
       "       'Gina Cartwright', 'Eshal Brandt', 'Macey Broughton',\n",
       "       'Igor Coates', 'Mohammad Velazquez', 'Martina Meadows'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uniques trainer name\n",
    "normalised_df['trainer'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Gregor Gomez', 'Bruce Lugo', 'Neil Mccarthy', 'Rachel Richard',\n",
       "       'Hamzah Melia', 'Burhan Milner', 'Elly Kelly', 'Trixie Orange',\n",
       "       'John Sandbox', 'Edward Reinhart', 'Lucy Foster',\n",
       "       'Gina Cartwright', 'Eshal Brandt', 'Macey Broughton',\n",
       "       'Igor Coates', 'Mohammad Velazquez', 'Martina Meadows'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correct the trainer name anomalies\n",
    "normalised_df['trainer'] = normalised_df['trainer'].replace('Ely Kely', 'Elly Kelly')\n",
    "normalised_df['trainer'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jr/dhzz03zd14b_2cf35k7btydh0000gn/T/ipykernel_9588/3329588578.py:2: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  normalised_df.groupby('trainer').mean().sort_values(by=['score'],ascending=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trainer</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lucy Foster</th>\n",
       "      <td>5.542977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Igor Coates</th>\n",
       "      <td>5.488462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eshal Brandt</th>\n",
       "      <td>5.369198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gina Cartwright</th>\n",
       "      <td>5.307018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Elly Kelly</th>\n",
       "      <td>5.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Macey Broughton</th>\n",
       "      <td>5.276803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>John Sandbox</th>\n",
       "      <td>5.254438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bruce Lugo</th>\n",
       "      <td>5.232297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gregor Gomez</th>\n",
       "      <td>5.211382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Edward Reinhart</th>\n",
       "      <td>5.200375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mohammad Velazquez</th>\n",
       "      <td>5.171821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Burhan Milner</th>\n",
       "      <td>5.122917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rachel Richard</th>\n",
       "      <td>5.084270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hamzah Melia</th>\n",
       "      <td>4.979798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Martina Meadows</th>\n",
       "      <td>4.959770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trixie Orange</th>\n",
       "      <td>4.951220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neil Mccarthy</th>\n",
       "      <td>4.907407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       score\n",
       "trainer                     \n",
       "Lucy Foster         5.542977\n",
       "Igor Coates         5.488462\n",
       "Eshal Brandt        5.369198\n",
       "Gina Cartwright     5.307018\n",
       "Elly Kelly          5.300000\n",
       "Macey Broughton     5.276803\n",
       "John Sandbox        5.254438\n",
       "Bruce Lugo          5.232297\n",
       "Gregor Gomez        5.211382\n",
       "Edward Reinhart     5.200375\n",
       "Mohammad Velazquez  5.171821\n",
       "Burhan Milner       5.122917\n",
       "Rachel Richard      5.084270\n",
       "Hamzah Melia        4.979798\n",
       "Martina Meadows     4.959770\n",
       "Trixie Orange       4.951220\n",
       "Neil Mccarthy       4.907407"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean score values by trainer\n",
    "normalised_df.groupby('trainer').mean().sort_values(by=['score'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jr/dhzz03zd14b_2cf35k7btydh0000gn/T/ipykernel_9588/182064997.py:2: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  normalised_df.groupby('name').mean().sort_values(by=['score'],ascending=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Violet Luscombe</th>\n",
       "      <td>6.383333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gabbey Caesman</th>\n",
       "      <td>6.116667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yalonda Beacom</th>\n",
       "      <td>6.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Auberon Werny</th>\n",
       "      <td>6.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reggie Lawlor</th>\n",
       "      <td>6.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quintus Penella</th>\n",
       "      <td>1.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Connor Gegg</th>\n",
       "      <td>1.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Teirtza Docharty</th>\n",
       "      <td>1.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dewitt Milborn</th>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Benita Downgate</th>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>397 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     score\n",
       "name                      \n",
       "Violet Luscombe   6.383333\n",
       "Gabbey Caesman    6.116667\n",
       "Yalonda Beacom    6.083333\n",
       "Auberon Werny     6.066667\n",
       "Reggie Lawlor     6.033333\n",
       "...                    ...\n",
       "Quintus Penella   1.666667\n",
       "Connor Gegg       1.666667\n",
       "Teirtza Docharty  1.666667\n",
       "Dewitt Milborn    1.500000\n",
       "Benita Downgate   1.333333\n",
       "\n",
       "[397 rows x 1 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean score values by trainee name\n",
    "normalised_df.groupby('name').mean().sort_values(by=['score'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23820 entries, 0 to 23819\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   name        23820 non-null  object \n",
      " 1   trainer     23820 non-null  object \n",
      " 2   course      23820 non-null  object \n",
      " 3   start_date  23820 non-null  object \n",
      " 4   score       19542 non-null  float64\n",
      " 5   trait       23820 non-null  object \n",
      " 6   week        23820 non-null  object \n",
      "dtypes: float64(1), object(6)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "normalised_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23820 entries, 0 to 23819\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   name        23820 non-null  object        \n",
      " 1   trainer     23820 non-null  object        \n",
      " 2   course      23820 non-null  object        \n",
      " 3   start_date  23820 non-null  datetime64[ns]\n",
      " 4   score       19542 non-null  float64       \n",
      " 5   trait       23820 non-null  object        \n",
      " 6   week        23820 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(1), int64(1), object(4)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "normalised_df['start_date'] = pd.to_datetime(normalised_df['start_date'])\n",
    "normalised_df['week'] = pd.to_numeric(normalised_df['week'])\n",
    "normalised_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe into a csv file\n",
    "normalised_df.to_csv('academy_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x174d18250>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect to MongoDB server\n",
    "client = MongoClient('mongodb://localhost:27017/')\n",
    "# Select the database\n",
    "db = client['Sparta']\n",
    "# Select the collection\n",
    "collection = db['Academy']\n",
    "\n",
    "# Create an empty dictionary to store the scores\n",
    "scores_dict = {}\n",
    "\n",
    "filename = 'academy_clean.csv'\n",
    "\n",
    "with open(filename) as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    # Skip header row\n",
    "    header = next(csv_reader)\n",
    "    # Loop through each row in the csv file\n",
    "    for row in csv_reader:\n",
    "        # Extract the fields from the row\n",
    "        name = row[1]\n",
    "        trainer = row[2]\n",
    "        course = row[3]\n",
    "        start_date = row[4]\n",
    "        score = row[5]\n",
    "        trait = row[6]\n",
    "        week = row[7]\n",
    "        # If the name is not already in the dictionary, add it\n",
    "        if name not in scores_dict:\n",
    "            scores_dict[name] = {'trainer': trainer, 'start_date': start_date, 'course': course, 'week':{}}\n",
    "        # If the course is not already in the dictionary, add it\n",
    "        if course not in scores_dict[name]['course']:\n",
    "            scores_dict[name]['course'].append(course)\n",
    "        # If the week is not already in the dictionary, add it\n",
    "        if week not in scores_dict[name]['week']:\n",
    "            scores_dict[name]['week'][week] = {}\n",
    "        # Convert the score to float if it exists or None if it's not a float\n",
    "        try:\n",
    "            score = float(score)\n",
    "        except (ValueError, TypeError):\n",
    "            score = None\n",
    "        # Add the score for the trait and week\n",
    "        scores_dict[name]['week'][week][trait] = score\n",
    "\n",
    "# Convert the dictionary to a list of documents\n",
    "documents = []\n",
    "for name, data in scores_dict.items():\n",
    "    documents.append({'name': name, 'trainer': data['trainer'], 'start_date': data['start_date'], 'course': data['course'], 'week': data['week']})\n",
    "\n",
    "# Insert the scores into the MongoDB collection\n",
    "collection.insert_many(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0214075810051456265b4c413eaea7f9f19f2f11ce5a028dc5233be0d3f2fb58"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
